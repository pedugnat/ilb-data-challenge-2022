{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:10.627853Z",
     "start_time": "2022-12-30T13:14:08.762170Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn.compose import (\n",
    "    make_column_transformer,\n",
    "    TransformedTargetRegressor,\n",
    ")\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import OrdinalEncoder as SKOrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:10.639298Z",
     "start_time": "2022-12-30T13:14:10.635787Z"
    }
   },
   "outputs": [],
   "source": [
    "# little snippet to normalize text by removing accents\n",
    "def strip_accents(text):\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except (TypeError, NameError): # unicode is a default on python 3 \n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = text.encode('ascii', 'ignore')\n",
    "    text = text.decode(\"utf-8\")\n",
    "    return str(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:10.644795Z",
     "start_time": "2022-12-30T13:14:10.641537Z"
    }
   },
   "outputs": [],
   "source": [
    "LAT_LONG_COLUMNS = [\"approximate_latitude\", \"approximate_longitude\"]\n",
    "\n",
    "N_CV_FOLDS = 10\n",
    "SCORING = \"neg_mean_absolute_percentage_error\"\n",
    "USE_IMAGE_EMBEDDING = True\n",
    "USE_DVF = True\n",
    "USE_SALARIES = True\n",
    "USE_MAGIC = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas on simple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:10.829893Z",
     "start_time": "2022-12-30T13:14:10.646894Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/X_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\")\n",
    "\n",
    "df_train[\"fold\"] = \"train\"\n",
    "df_test[\"fold\"] = \"test\"\n",
    "\n",
    "df_all = pd.concat([df_train, df_test], axis=0)\n",
    "data_all = pd.merge(df_all, y_train, on=\"id_annonce\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:10.859687Z",
     "start_time": "2022-12-30T13:14:10.831907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_annonce</th>\n",
       "      <th>property_type</th>\n",
       "      <th>approximate_latitude</th>\n",
       "      <th>approximate_longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>size</th>\n",
       "      <th>floor</th>\n",
       "      <th>land_size</th>\n",
       "      <th>energy_performance_value</th>\n",
       "      <th>energy_performance_category</th>\n",
       "      <th>ghg_value</th>\n",
       "      <th>ghg_category</th>\n",
       "      <th>exposition</th>\n",
       "      <th>nb_rooms</th>\n",
       "      <th>nb_bedrooms</th>\n",
       "      <th>nb_bathrooms</th>\n",
       "      <th>nb_parking_places</th>\n",
       "      <th>nb_boxes</th>\n",
       "      <th>nb_photos</th>\n",
       "      <th>has_a_balcony</th>\n",
       "      <th>nb_terraces</th>\n",
       "      <th>has_a_cellar</th>\n",
       "      <th>has_a_garage</th>\n",
       "      <th>has_air_conditioning</th>\n",
       "      <th>last_floor</th>\n",
       "      <th>upper_floors</th>\n",
       "      <th>fold</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35996577</td>\n",
       "      <td>appartement</td>\n",
       "      <td>43.643880</td>\n",
       "      <td>7.117183</td>\n",
       "      <td>villeneuve-loubet</td>\n",
       "      <td>6270</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>355000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35811033</td>\n",
       "      <td>appartement</td>\n",
       "      <td>45.695757</td>\n",
       "      <td>4.895610</td>\n",
       "      <td>venissieux</td>\n",
       "      <td>69200</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.0</td>\n",
       "      <td>D</td>\n",
       "      <td>52.0</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>190000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35731841</td>\n",
       "      <td>maison</td>\n",
       "      <td>47.966791</td>\n",
       "      <td>-1.220451</td>\n",
       "      <td>moutiers</td>\n",
       "      <td>35130</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>370.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sud</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>39000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35886765</td>\n",
       "      <td>maison</td>\n",
       "      <td>47.289292</td>\n",
       "      <td>-1.878805</td>\n",
       "      <td>cordemais</td>\n",
       "      <td>44360</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>764.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>D</td>\n",
       "      <td>44.0</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>299000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35781137</td>\n",
       "      <td>appartement</td>\n",
       "      <td>45.718992</td>\n",
       "      <td>4.844234</td>\n",
       "      <td>lyon-7eme</td>\n",
       "      <td>69007</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>478000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_annonce property_type  approximate_latitude  approximate_longitude  \\\n",
       "0    35996577   appartement             43.643880               7.117183   \n",
       "1    35811033   appartement             45.695757               4.895610   \n",
       "2    35731841        maison             47.966791              -1.220451   \n",
       "3    35886765        maison             47.289292              -1.878805   \n",
       "4    35781137   appartement             45.718992               4.844234   \n",
       "\n",
       "                city  postal_code   size  floor  land_size  \\\n",
       "0  villeneuve-loubet         6270   63.0    NaN        NaN   \n",
       "1         venissieux        69200   90.0    3.0        NaN   \n",
       "2           moutiers        35130   61.0    NaN      370.0   \n",
       "3          cordemais        44360  142.0    NaN      764.0   \n",
       "4          lyon-7eme        69007   88.0    3.0        NaN   \n",
       "\n",
       "   energy_performance_value energy_performance_category  ghg_value  \\\n",
       "0                       NaN                         NaN        NaN   \n",
       "1                     223.0                           D       52.0   \n",
       "2                       NaN                         NaN        NaN   \n",
       "3                     217.0                           D       44.0   \n",
       "4                       NaN                         NaN        NaN   \n",
       "\n",
       "  ghg_category exposition  nb_rooms  nb_bedrooms  nb_bathrooms  \\\n",
       "0          NaN        NaN       3.0          2.0           NaN   \n",
       "1            E        NaN       5.0          4.0           NaN   \n",
       "2          NaN        Sud       2.0          1.0           NaN   \n",
       "3            E        NaN       4.0          3.0           NaN   \n",
       "4          NaN        NaN       4.0          3.0           1.0   \n",
       "\n",
       "   nb_parking_places  nb_boxes  nb_photos  has_a_balcony  nb_terraces  \\\n",
       "0                0.0       0.0        4.0            0.0          1.0   \n",
       "1                0.0       0.0        8.0            0.0          0.0   \n",
       "2                0.0       0.0        4.0            0.0          0.0   \n",
       "3                0.0       1.0        8.0            0.0          1.0   \n",
       "4                0.0       1.0        5.0            1.0          0.0   \n",
       "\n",
       "   has_a_cellar  has_a_garage  has_air_conditioning  last_floor  upper_floors  \\\n",
       "0           0.0           0.0                   0.0         0.0           0.0   \n",
       "1           0.0           0.0                   0.0         0.0           0.0   \n",
       "2           0.0           0.0                   0.0         0.0           0.0   \n",
       "3           0.0           0.0                   0.0         0.0           0.0   \n",
       "4           0.0           0.0                   0.0         0.0           0.0   \n",
       "\n",
       "    fold     price  \n",
       "0  train  355000.0  \n",
       "1  train  190000.0  \n",
       "2  train   39000.0  \n",
       "3  train  299000.0  \n",
       "4  train  478000.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.089923Z",
     "start_time": "2022-12-30T13:14:10.862604Z"
    }
   },
   "outputs": [],
   "source": [
    "data_all[\"departement\"] = data_all[\"postal_code\"].astype(\n",
    "    str).str[:-3].str.zfill(2)\n",
    "\n",
    "data_all[\"post_code_suffix\"] = data_all[\"postal_code\"] % 1000\n",
    "\n",
    "data_all[\"city_enc\"] = data_all[\"city\"]\n",
    "\n",
    "# a few basic ratios\n",
    "data_all[\"nb_bedrooms_over_rooms\"] = data_all[\"nb_bedrooms\"].div(\n",
    "    data_all[\"nb_rooms\"].replace(0.0, np.nan)\n",
    ")\n",
    "data_all[\"size_over_rooms\"] = data_all[\"size\"].div(\n",
    "    data_all[\"nb_rooms\"].replace(0.0, np.nan)\n",
    ")\n",
    "data_all[\"size_over_landsize\"] = data_all[\"size\"].div(\n",
    "    data_all[\"land_size\"].replace(0.0, np.nan)\n",
    ")\n",
    "data_all[\"sqrt_size\"] = np.sqrt(data_all[\"size\"])\n",
    "\n",
    "# interaction columns\n",
    "data_all[\"type_rooms\"] = data_all[\"property_type\"] + data_all[\"nb_rooms\"].clip(\n",
    "    None, 8.0\n",
    ").fillna(\"nan\").astype(str)\n",
    "data_all[\"type_bedrooms\"] = data_all[\"property_type\"] + data_all[\"nb_bedrooms\"].clip(\n",
    "    None, 6.0\n",
    ").fillna(\"nan\").astype(str)\n",
    "data_all[\"city_property_type\"] = (\n",
    "    data_all[\"city\"] + data_all[\"property_type\"]).astype(str)\n",
    "data_all[\"departement_property_type\"] = (\n",
    "    data_all[\"departement\"] + data_all[\"property_type\"]).astype(str)\n",
    "data_all[\"city_nb_rooms\"] = (\n",
    "    data_all[\"city\"] + data_all[\"nb_rooms\"].astype(str)).astype(str)\n",
    "data_all[\"departement_nb_rooms\"] = (\n",
    "    data_all[\"departement\"] + data_all[\"nb_rooms\"].astype(str)).astype(str)\n",
    "\n",
    "data_all = data_all.rename(columns={\"nb_terraces\": \"has_a_terrace\"})\n",
    "\n",
    "data_all[\"diff_size_per_departement\"] = (\n",
    "    data_all[\"size\"] - \n",
    "    data_all.groupby([\"departement\", \"property_type\"])[\"size\"].transform(\"mean\")\n",
    ")\n",
    "data_all[\"diff_size_per_city\"] = (\n",
    "    data_all[\"size\"] - \n",
    "    data_all.groupby([\"city\", \"property_type\"])[\"size\"].transform(\"mean\")\n",
    ")\n",
    "data_all[\"diff_landsize_per_city\"] = (\n",
    "    data_all[\"land_size\"] - \n",
    "    data_all.groupby([\"city\", \"property_type\"])[\"land_size\"].transform(\"mean\"))\n",
    "\n",
    "# drop useless indicators\n",
    "data_all = data_all.drop([\"upper_floors\", \"last_floor\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate image prediction as a feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.198182Z",
     "start_time": "2022-12-30T13:14:11.092483Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_IMAGE_EMBEDDING:\n",
    "    image_pred_mix_train = pd.read_csv(\"../images_features_effnet_resnet_train.csv\")\n",
    "    image_pred_mix_test = pd.read_csv(\"../images_features_effnet_resnet_test.csv\")\n",
    "    \n",
    "    image_pred_mix = pd.concat((image_pred_mix_train, image_pred_mix_test), axis=0)\n",
    "\n",
    "    data_all = pd.merge(data_all, image_pred_mix[[\"id_annonce\", \"price_pred\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.323820Z",
     "start_time": "2022-12-30T13:14:11.203614Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_DVF:\n",
    "    dvf = pd.read_csv(\"../data/dvf_codepostal.csv\")\n",
    "\n",
    "    data_all = pd.merge(\n",
    "        data_all,\n",
    "        dvf.rename(columns={\"Code postal\": \"postal_code\"}),\n",
    "        on=\"postal_code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    dvf = pd.read_csv(\"../data/dvf_codepostal_pieces.csv\")\n",
    "\n",
    "    data_all = pd.merge(\n",
    "        data_all,\n",
    "        dvf.rename(columns={\n",
    "            \"Code postal\": \"postal_code\",\n",
    "            \"Nombre pieces principales\": \"nb_rooms\"\n",
    "        }),\n",
    "        on=[\"postal_code\", \"nb_rooms\"],\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_pc\", \"_rooms\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.409394Z",
     "start_time": "2022-12-30T13:14:11.326290Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_SALARIES:\n",
    "    # add salary per city\n",
    "    df_salaires_villes = pd.read_csv(\"../data/salaires_villes.csv\")\n",
    "    df_salaires_villes[\"city\"] = df_salaires_villes[\"city\"].apply(\n",
    "        strip_accents)\n",
    "\n",
    "    data_all = pd.merge(\n",
    "        data_all,\n",
    "        df_salaires_villes[[\"city\", \"SNHM19\"]],\n",
    "        on=\"city\",\n",
    "        how='left')\n",
    "\n",
    "    # add salary per departements\n",
    "    df_salaires_departements = pd.read_csv(\"../data/salaires_departements.csv\")\n",
    "    data_all = pd.merge(\n",
    "        data_all,\n",
    "        df_salaires_departements[[\"departement\", \"SNHM19_dep\"]],\n",
    "        on=\"departement\",\n",
    "        how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.456999Z",
     "start_time": "2022-12-30T13:14:11.411766Z"
    }
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\n",
    "    \"property_type\",\n",
    "    \"exposition\",\n",
    "    \"has_a_balcony\",\n",
    "    \"has_a_terrace\",\n",
    "    \"has_a_cellar\",\n",
    "    \"has_a_garage\",\n",
    "    \"has_air_conditioning\",\n",
    "    \"energy_performance_category\",\n",
    "    \"ghg_category\",\n",
    "    \"type_rooms\",\n",
    "    \"type_bedrooms\",\n",
    "    \"city\",\n",
    "]\n",
    "\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    data_all[col] = data_all[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.514840Z",
     "start_time": "2022-12-30T13:14:11.459538Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = data_all.query(\"fold=='train'\").drop(\"fold\", axis=1)\n",
    "data_test = data_all.query(\"fold=='test'\").drop(\"fold\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.537255Z",
     "start_time": "2022-12-30T13:14:11.517624Z"
    },
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "# quick patch to add normalization capability\n",
    "\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "import category_encoders.utils as util\n",
    "\n",
    "\n",
    "class TargetEncoder(BaseEstimator, util.TransformerWithTargetMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        verbose=0,\n",
    "        cols=None,\n",
    "        drop_invariant=False,\n",
    "        return_df=True,\n",
    "        handle_missing=\"value\",\n",
    "        handle_unknown=\"value\",\n",
    "        min_samples_leaf=1,\n",
    "        smoothing=1.0,\n",
    "        normalize=False,\n",
    "    ):\n",
    "        self.return_df = return_df\n",
    "        self.drop_invariant = drop_invariant\n",
    "        self.drop_cols = []\n",
    "        self.verbose = verbose\n",
    "        self.cols = cols\n",
    "        self.ordinal_encoder = None\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.smoothing = float(\n",
    "            smoothing\n",
    "        )  # Make smoothing a float so that python 2 does not treat as integer division\n",
    "        self._dim = None\n",
    "        self.mapping = None\n",
    "        self.handle_unknown = handle_unknown\n",
    "        self.handle_missing = handle_missing\n",
    "        self._mean = None\n",
    "        self.feature_names = None\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        \"\"\"Fit encoder according to X and y.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # unite the input into pandas types\n",
    "        X = util.convert_input(X)\n",
    "        y = util.convert_input_vector(y, X.index)\n",
    "\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\n",
    "                \"The length of X is \"\n",
    "                + str(X.shape[0])\n",
    "                + \" but length of y is \"\n",
    "                + str(y.shape[0])\n",
    "                + \".\"\n",
    "            )\n",
    "\n",
    "        self._dim = X.shape[1]\n",
    "\n",
    "        # if columns aren't passed, just use every string column\n",
    "        if self.cols is None:\n",
    "            self.cols = util.get_obj_cols(X)\n",
    "        else:\n",
    "            self.cols = util.convert_cols_to_list(self.cols)\n",
    "\n",
    "        if self.handle_missing == \"error\":\n",
    "            if X[self.cols].isnull().any().any():\n",
    "                raise ValueError(\"Columns to be encoded can not contain null\")\n",
    "\n",
    "        self.ordinal_encoder = OrdinalEncoder(\n",
    "            verbose=self.verbose,\n",
    "            cols=self.cols,\n",
    "            handle_unknown=\"value\",\n",
    "            handle_missing=\"value\",\n",
    "        )\n",
    "        self.ordinal_encoder = self.ordinal_encoder.fit(X)\n",
    "        X_ordinal = self.ordinal_encoder.transform(X)\n",
    "        self.mapping = self.fit_target_encoding(X_ordinal, y)\n",
    "\n",
    "        X_temp = self.transform(X, override_return_df=True)\n",
    "        self.feature_names = list(X_temp.columns)\n",
    "\n",
    "        if self.drop_invariant:\n",
    "            self.drop_cols = []\n",
    "            X_temp = self.transform(X)\n",
    "            generated_cols = util.get_generated_cols(X, X_temp, self.cols)\n",
    "            self.drop_cols = [\n",
    "                x for x in generated_cols if X_temp[x].var() <= 10e-5]\n",
    "            try:\n",
    "                [self.feature_names.remove(x) for x in self.drop_cols]\n",
    "            except KeyError as e:\n",
    "                if self.verbose > 0:\n",
    "                    print(\n",
    "                        \"Could not remove column from feature names.\"\n",
    "                        \"Not found in generated cols.\\n{}\".format(e)\n",
    "                    )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit_target_encoding(self, X, y):\n",
    "        mapping = {}\n",
    "\n",
    "        for switch in self.ordinal_encoder.category_mapping:\n",
    "            col = switch.get(\"col\")\n",
    "            values = switch.get(\"mapping\")\n",
    "\n",
    "            prior = self._mean = y.mean()\n",
    "\n",
    "            if self.normalize:\n",
    "                normalizer = X[\"size\"].replace(0.0, np.nan).values\n",
    "            else:\n",
    "                normalizer = 1\n",
    "            stats = (y / normalizer).replace([-np.inf, np.inf],\n",
    "                                             np.nan).groupby(X[col]).agg([\"count\", \"mean\"])\n",
    "\n",
    "            smoove = 1 / (\n",
    "                1 + np.exp(-(stats[\"count\"] -\n",
    "                             self.min_samples_leaf) / self.smoothing)\n",
    "            )\n",
    "            smoothing = prior * (1 - smoove) + stats[\"mean\"] * smoove\n",
    "            smoothing[stats[\"count\"] == 1] = prior\n",
    "\n",
    "            if self.handle_unknown == \"return_nan\":\n",
    "                smoothing.loc[-1] = np.nan\n",
    "            elif self.handle_unknown == \"value\":\n",
    "                smoothing.loc[-1] = prior\n",
    "\n",
    "            if self.handle_missing == \"return_nan\":\n",
    "                smoothing.loc[values.loc[np.nan]] = np.nan\n",
    "            elif self.handle_missing == \"value\":\n",
    "                smoothing.loc[-2] = prior\n",
    "\n",
    "            mapping[col] = smoothing\n",
    "\n",
    "        return mapping\n",
    "\n",
    "    def transform(self, X, y=None, override_return_df=False):\n",
    "        \"\"\"Perform the transformation to new categorical data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "        y : array-like, shape = [n_samples] when transform by leave one out\n",
    "            None, when transform without target info (such as transform test set)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p : array, shape = [n_samples, n_numeric + N]\n",
    "            Transformed values with encoding applied.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.handle_missing == \"error\":\n",
    "            if X[self.cols].isnull().any().any():\n",
    "                raise ValueError(\"Columns to be encoded can not contain null\")\n",
    "\n",
    "        if self._dim is None:\n",
    "            raise ValueError(\n",
    "                \"Must train encoder before it can be used to transform data.\"\n",
    "            )\n",
    "\n",
    "        # unite the input into pandas types\n",
    "        X = util.convert_input(X)\n",
    "\n",
    "        # then make sure that it is the right size\n",
    "        if X.shape[1] != self._dim:\n",
    "            raise ValueError(\n",
    "                \"Unexpected input dimension %d, expected %d\"\n",
    "                % (\n",
    "                    X.shape[1],\n",
    "                    self._dim,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # if we are encoding the training data, we have to check the target\n",
    "        if y is not None:\n",
    "            y = util.convert_input_vector(y, X.index)\n",
    "            if X.shape[0] != y.shape[0]:\n",
    "                raise ValueError(\n",
    "                    \"The length of X is \"\n",
    "                    + str(X.shape[0])\n",
    "                    + \" but length of y is \"\n",
    "                    + str(y.shape[0])\n",
    "                    + \".\"\n",
    "                )\n",
    "\n",
    "        if not list(self.cols):\n",
    "            return X\n",
    "\n",
    "        X = self.ordinal_encoder.transform(X)\n",
    "\n",
    "        if self.handle_unknown == \"error\":\n",
    "            if X[self.cols].isin([-1]).any().any():\n",
    "                raise ValueError(\"Unexpected categories found in dataframe\")\n",
    "\n",
    "        X = self.target_encode(X)\n",
    "\n",
    "        if self.drop_invariant:\n",
    "            for col in self.drop_cols:\n",
    "                X.drop(col, 1, inplace=True)\n",
    "\n",
    "        if self.return_df or override_return_df:\n",
    "            return X\n",
    "        else:\n",
    "            return X.values\n",
    "\n",
    "    def target_encode(self, X_in):\n",
    "        X = X_in.copy(deep=True)\n",
    "\n",
    "        for col in self.cols:\n",
    "            X[col] = X[col].map(self.mapping[col])\n",
    "\n",
    "        return X\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        \"\"\"\n",
    "        Returns the names of all transformed / added columns.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        feature_names: list\n",
    "            A list with all feature names transformed or added.\n",
    "            Note: potentially dropped features are not included!\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(self.feature_names, list):\n",
    "            raise ValueError(\n",
    "                \"Must fit data first. Affected feature names are not known before.\"\n",
    "            )\n",
    "        else:\n",
    "            return self.feature_names\n",
    "        \n",
    "    def get_feature_names_out(self):\n",
    "        \"\"\"\n",
    "        Returns the names of all transformed / added columns.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        feature_names: list\n",
    "            A list with all feature names transformed or added.\n",
    "            Note: potentially dropped features are not included!\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(self.feature_names, list):\n",
    "            raise ValueError(\n",
    "                \"Must fit data first. Affected feature names are not known before.\"\n",
    "            )\n",
    "        else:\n",
    "            return self.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.543997Z",
     "start_time": "2022-12-30T13:14:11.539778Z"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_encoder = make_column_transformer(\n",
    "    (\n",
    "        SKOrdinalEncoder(\n",
    "            handle_unknown=\"use_encoded_value\",\n",
    "            unknown_value=np.nan\n",
    "        ),\n",
    "        CATEGORICAL_COLUMNS,\n",
    "    ),\n",
    "    (\n",
    "        TargetEncoder(verbose=1, normalize=True),\n",
    "        [\n",
    "             \"city_enc\", \n",
    "             \"departement\", \n",
    "             \"city_property_type\",\n",
    "             \"departement_property_type\", \n",
    "             \"city_nb_rooms\", \n",
    "             \"departement_nb_rooms\", \n",
    "             \"size\"\n",
    "        ],\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.551569Z",
     "start_time": "2022-12-30T13:14:11.546110Z"
    }
   },
   "outputs": [],
   "source": [
    "# magic feature : compute mean price of n-closest houses\n",
    "class NNTransformer(TransformerMixin):\n",
    "    \"\"\"Compute the mean price per square-meter in a given radius.\"\"\"\n",
    "    def __init__(self, n_neighbors, columns, normalize=False):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.columns = columns\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def fit(self, X_train, y):\n",
    "        self.nearest_neighbors = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "\n",
    "        data_train = X_train[self.columns].fillna(0)\n",
    "        self.nearest_neighbors.fit(data_train)\n",
    "\n",
    "        if self.normalize:\n",
    "            # normalize prices by size to have the price per square meters\n",
    "            self.prices = (\n",
    "                (y / X_train[\"size\"])\n",
    "                .replace([-np.inf, np.inf], np.nan)\n",
    "                .values\n",
    "            )\n",
    "        else:\n",
    "            self.prices = y.values\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_all):\n",
    "        data_all = X_all[self.columns].fillna(0)\n",
    "        neighbors_id = self.nearest_neighbors.kneighbors(data_all)[1]\n",
    "        \n",
    "        neighbors_price = np.array(\n",
    "            [np.nanmean(self.prices[neighbors_id[:, 1:]], axis=1)]\n",
    "        ).T\n",
    "        \n",
    "        return neighbors_price\n",
    "    \n",
    "    def get_feature_names_out(self, input_features):\n",
    "        return f\"nearest_{self.n_neighbors}_mean_price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.558815Z",
     "start_time": "2022-12-30T13:14:11.554243Z"
    }
   },
   "outputs": [],
   "source": [
    "class RadiusTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Count the number of houses in the dataset in a given radius.\"\"\"\n",
    "    def __init__(self, radius, columns):\n",
    "        self.radius = radius\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X_train, y):\n",
    "        self.rn = NearestNeighbors()\n",
    "        \n",
    "        data_train = X_train[self.columns]\n",
    "        self.rn.fit(data_train)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X_all):\n",
    "        data_all = X_all[self.columns]\n",
    "        \n",
    "        nn_kneighbors = self.rn.radius_neighbors(data_all, radius=self.radius)[1]\n",
    "        \n",
    "        return np.array([[len(neigh) for neigh in nn_kneighbors]]).T\n",
    "    \n",
    "    def get_feature_names_out(self, input_features):\n",
    "        return f\"radius_{self.radius}_density\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.565292Z",
     "start_time": "2022-12-30T13:14:11.561358Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_MAGIC:\n",
    "    ranges_nnt = range(3, 11, 1)\n",
    "    ranges_rt = range(0, 8, 1)\n",
    "else:\n",
    "    ranges_nnt = []\n",
    "    ranges_rt = []\n",
    "    \n",
    "feats = make_union(\n",
    "    ordinal_encoder,\n",
    "    *(\n",
    "        NNTransformer(\n",
    "            n_neighbors=2 ** i,\n",
    "            columns=LAT_LONG_COLUMNS,\n",
    "            normalize=True\n",
    "        )\n",
    "        for i in ranges_nnt\n",
    "    ),\n",
    "    *(RadiusTransformer(1 / (2 ** i), LAT_LONG_COLUMNS) for i in ranges_rt),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.596746Z",
     "start_time": "2022-12-30T13:14:11.566883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_annonce</th>\n",
       "      <th>property_type</th>\n",
       "      <th>approximate_latitude</th>\n",
       "      <th>approximate_longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>size</th>\n",
       "      <th>floor</th>\n",
       "      <th>land_size</th>\n",
       "      <th>energy_performance_value</th>\n",
       "      <th>energy_performance_category</th>\n",
       "      <th>ghg_value</th>\n",
       "      <th>ghg_category</th>\n",
       "      <th>exposition</th>\n",
       "      <th>nb_rooms</th>\n",
       "      <th>nb_bedrooms</th>\n",
       "      <th>nb_bathrooms</th>\n",
       "      <th>nb_parking_places</th>\n",
       "      <th>nb_boxes</th>\n",
       "      <th>nb_photos</th>\n",
       "      <th>has_a_balcony</th>\n",
       "      <th>has_a_terrace</th>\n",
       "      <th>has_a_cellar</th>\n",
       "      <th>has_a_garage</th>\n",
       "      <th>has_air_conditioning</th>\n",
       "      <th>price</th>\n",
       "      <th>departement</th>\n",
       "      <th>post_code_suffix</th>\n",
       "      <th>city_enc</th>\n",
       "      <th>nb_bedrooms_over_rooms</th>\n",
       "      <th>size_over_rooms</th>\n",
       "      <th>size_over_landsize</th>\n",
       "      <th>sqrt_size</th>\n",
       "      <th>type_rooms</th>\n",
       "      <th>type_bedrooms</th>\n",
       "      <th>city_property_type</th>\n",
       "      <th>departement_property_type</th>\n",
       "      <th>city_nb_rooms</th>\n",
       "      <th>departement_nb_rooms</th>\n",
       "      <th>diff_size_per_departement</th>\n",
       "      <th>diff_size_per_city</th>\n",
       "      <th>diff_landsize_per_city</th>\n",
       "      <th>price_pred</th>\n",
       "      <th>Surface reelle bati_pc</th>\n",
       "      <th>Surface terrain_pc</th>\n",
       "      <th>Valeur fonciere_pc</th>\n",
       "      <th>Nombre pieces principales</th>\n",
       "      <th>prix_metre_carre_pc</th>\n",
       "      <th>prix_metre_carre_terrain_pc</th>\n",
       "      <th>Surface reelle bati_rooms</th>\n",
       "      <th>Surface terrain_rooms</th>\n",
       "      <th>Valeur fonciere_rooms</th>\n",
       "      <th>prix_metre_carre_rooms</th>\n",
       "      <th>prix_metre_carre_terrain_rooms</th>\n",
       "      <th>SNHM19</th>\n",
       "      <th>SNHM19_dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35996577</td>\n",
       "      <td>appartement</td>\n",
       "      <td>43.643880</td>\n",
       "      <td>7.117183</td>\n",
       "      <td>villeneuve-loubet</td>\n",
       "      <td>6270</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355000.0</td>\n",
       "      <td>06</td>\n",
       "      <td>270</td>\n",
       "      <td>villeneuve-loubet</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.937254</td>\n",
       "      <td>appartement3.0</td>\n",
       "      <td>appartement2.0</td>\n",
       "      <td>villeneuve-loubetappartement</td>\n",
       "      <td>06appartement</td>\n",
       "      <td>villeneuve-loubet3.0</td>\n",
       "      <td>063.0</td>\n",
       "      <td>-1269.792230</td>\n",
       "      <td>-1622.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243192.935182</td>\n",
       "      <td>74.418048</td>\n",
       "      <td>601.351351</td>\n",
       "      <td>332958.364364</td>\n",
       "      <td>1.318854</td>\n",
       "      <td>5422.001419</td>\n",
       "      <td>7721.291671</td>\n",
       "      <td>68.088000</td>\n",
       "      <td>501.333333</td>\n",
       "      <td>350521.26424</td>\n",
       "      <td>5164.200709</td>\n",
       "      <td>1978.664430</td>\n",
       "      <td>16.478742</td>\n",
       "      <td>15.48594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35811033</td>\n",
       "      <td>appartement</td>\n",
       "      <td>45.695757</td>\n",
       "      <td>4.895610</td>\n",
       "      <td>venissieux</td>\n",
       "      <td>69200</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.0</td>\n",
       "      <td>D</td>\n",
       "      <td>52.0</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>69</td>\n",
       "      <td>200</td>\n",
       "      <td>venissieux</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.486833</td>\n",
       "      <td>appartement5.0</td>\n",
       "      <td>appartement4.0</td>\n",
       "      <td>venissieuxappartement</td>\n",
       "      <td>69appartement</td>\n",
       "      <td>venissieux5.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>-1361.143564</td>\n",
       "      <td>-228.906977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170271.593424</td>\n",
       "      <td>90.151149</td>\n",
       "      <td>771.232456</td>\n",
       "      <td>305309.423628</td>\n",
       "      <td>1.777011</td>\n",
       "      <td>6152.318233</td>\n",
       "      <td>2445.067978</td>\n",
       "      <td>98.508475</td>\n",
       "      <td>579.608696</td>\n",
       "      <td>252607.00000</td>\n",
       "      <td>2589.887880</td>\n",
       "      <td>851.321408</td>\n",
       "      <td>12.531494</td>\n",
       "      <td>16.72526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_annonce property_type  approximate_latitude  approximate_longitude  \\\n",
       "0    35996577   appartement             43.643880               7.117183   \n",
       "1    35811033   appartement             45.695757               4.895610   \n",
       "\n",
       "                city  postal_code  size  floor  land_size  \\\n",
       "0  villeneuve-loubet         6270  63.0    NaN        NaN   \n",
       "1         venissieux        69200  90.0    3.0        NaN   \n",
       "\n",
       "   energy_performance_value energy_performance_category  ghg_value  \\\n",
       "0                       NaN                         NaN        NaN   \n",
       "1                     223.0                           D       52.0   \n",
       "\n",
       "  ghg_category exposition  nb_rooms  nb_bedrooms  nb_bathrooms  \\\n",
       "0          NaN        NaN       3.0          2.0           NaN   \n",
       "1            E        NaN       5.0          4.0           NaN   \n",
       "\n",
       "   nb_parking_places  nb_boxes  nb_photos has_a_balcony has_a_terrace  \\\n",
       "0                0.0       0.0        4.0           0.0           1.0   \n",
       "1                0.0       0.0        8.0           0.0           0.0   \n",
       "\n",
       "  has_a_cellar has_a_garage has_air_conditioning     price departement  \\\n",
       "0          0.0          0.0                  0.0  355000.0          06   \n",
       "1          0.0          0.0                  0.0  190000.0          69   \n",
       "\n",
       "   post_code_suffix           city_enc  nb_bedrooms_over_rooms  \\\n",
       "0               270  villeneuve-loubet                0.666667   \n",
       "1               200         venissieux                0.800000   \n",
       "\n",
       "   size_over_rooms  size_over_landsize  sqrt_size      type_rooms  \\\n",
       "0             21.0                 NaN   7.937254  appartement3.0   \n",
       "1             18.0                 NaN   9.486833  appartement5.0   \n",
       "\n",
       "    type_bedrooms            city_property_type departement_property_type  \\\n",
       "0  appartement2.0  villeneuve-loubetappartement             06appartement   \n",
       "1  appartement4.0         venissieuxappartement             69appartement   \n",
       "\n",
       "          city_nb_rooms departement_nb_rooms  diff_size_per_departement  \\\n",
       "0  villeneuve-loubet3.0                063.0               -1269.792230   \n",
       "1         venissieux5.0                695.0               -1361.143564   \n",
       "\n",
       "   diff_size_per_city  diff_landsize_per_city     price_pred  \\\n",
       "0        -1622.600000                     NaN  243192.935182   \n",
       "1         -228.906977                     NaN  170271.593424   \n",
       "\n",
       "   Surface reelle bati_pc  Surface terrain_pc  Valeur fonciere_pc  \\\n",
       "0               74.418048          601.351351       332958.364364   \n",
       "1               90.151149          771.232456       305309.423628   \n",
       "\n",
       "   Nombre pieces principales  prix_metre_carre_pc  \\\n",
       "0                   1.318854          5422.001419   \n",
       "1                   1.777011          6152.318233   \n",
       "\n",
       "   prix_metre_carre_terrain_pc  Surface reelle bati_rooms  \\\n",
       "0                  7721.291671                  68.088000   \n",
       "1                  2445.067978                  98.508475   \n",
       "\n",
       "   Surface terrain_rooms  Valeur fonciere_rooms  prix_metre_carre_rooms  \\\n",
       "0             501.333333           350521.26424             5164.200709   \n",
       "1             579.608696           252607.00000             2589.887880   \n",
       "\n",
       "   prix_metre_carre_terrain_rooms     SNHM19  SNHM19_dep  \n",
       "0                     1978.664430  16.478742    15.48594  \n",
       "1                      851.321408  12.531494    16.72526  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:14:11.620853Z",
     "start_time": "2022-12-30T13:14:11.598901Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data_train.drop(\"price\", axis=1)\n",
    "y = data_train[\"price\"]\n",
    "\n",
    "n_categorical = (data_train.dtypes.iloc[:-1] == \"category\").values.sum()\n",
    "categorical_mask = list(range(n_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:20:01.596459Z",
     "start_time": "2022-12-30T13:14:11.628083Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  4.1min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean over val set = 22.4%\n",
      "Mean over train set = 2.3%\n",
      "\n",
      "CPU times: user 9.17 s, sys: 2.73 s, total: 11.9 s\n",
      "Wall time: 5min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  5.8min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hgb = lightgbm.LGBMRegressor(\n",
    "    random_state=42,\n",
    "    categorical_features=categorical_mask,\n",
    "    n_estimators=2_000,\n",
    "    learning_rate=0.025,\n",
    "    num_leaves=256,\n",
    "    min_child_samples=10,\n",
    "    colsample_bytree=0.25,\n",
    ")\n",
    "\n",
    "hist_native = make_pipeline(\n",
    "    feats,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=hgb,\n",
    "        func=np.log,\n",
    "        inverse_func=np.exp,\n",
    "    ),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "results = cross_validate(\n",
    "    hist_native,\n",
    "    X,\n",
    "    y,\n",
    "    cv=N_CV_FOLDS,\n",
    "    scoring=SCORING,\n",
    "    return_estimator=True,\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(f\"Mean over val set = {-results['test_score'].mean():.1%}\")\n",
    "print(f\"Mean over train set = {-results['train_score'].mean():.1%}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:25:22.596427Z",
     "start_time": "2022-02-15T18:25:22.592800Z"
    }
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:20:56.886575Z",
     "start_time": "2022-12-30T13:20:01.602063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017587900161743164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 32,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8d6c3b5585447da8b2fc51f300926d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_test = data_test[~data_test.duplicated(subset=\"id_annonce\")]\n",
    "\n",
    "predictions = list()\n",
    "\n",
    "for estimator in tqdm(results[\"estimator\"]):\n",
    "    raw_pred = estimator.predict(data_test.drop(\"price\", axis=1))\n",
    "    pred = pd.Series(raw_pred, index=data_test[\"id_annonce\"])\n",
    "    predictions.append(pred)\n",
    "\n",
    "predictions = pd.concat(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T13:28:52.251107Z",
     "start_time": "2022-12-30T13:28:52.245749Z"
    }
   },
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "\n",
    "if SAVE:\n",
    "    k_rd = np.random.randint(0, 1_000) # kind of a hash of the version\n",
    "    predictions.to_csv(f\"../predictions/{k_rd}.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved to path: ../predictions/{k_rd}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
